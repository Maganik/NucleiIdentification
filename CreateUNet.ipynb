{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des librairies necessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import time\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D,Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition des fonctions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    folders = []\n",
    "    training_set = dict()\n",
    "    idx = 0\n",
    "\n",
    "    p = pathlib.Path(\"DATA/train/\")\n",
    "\n",
    "    #Looking for all the folders existing in train folder\n",
    "    for i in p.glob('*'):\n",
    "\n",
    "        path = \"DATA/train/\"\n",
    "        path += i.name;\n",
    "\n",
    "        f_path = pathlib.Path(path)\n",
    "        folders.append(f_path)\n",
    "\n",
    "\n",
    "    for p in folders:\n",
    "\n",
    "        im_p = str(p)\n",
    "        im_p += \"/images/\"\n",
    "        ma_p = str(p)\n",
    "        ma_p += \"/masks/\"\n",
    "\n",
    "        #First, we set the paths for the image and the masks\n",
    "\n",
    "        im_path = pathlib.Path(im_p)\n",
    "        ma_path = pathlib.Path(ma_p)\n",
    "\n",
    "\n",
    "        #Then, we read the image\n",
    "        name =\"\"\n",
    "        for i in im_path.glob('*.png'):\n",
    "            name = i.name\n",
    "        im_p += name\n",
    "        im = rgb2gray(imageio.imread(im_p))\n",
    "\n",
    "\n",
    "        masks = []\n",
    "        #Then, we read every sub mask\n",
    "        maskp = ma_p\n",
    "        for i in ma_path.glob('*.png'):\n",
    "            name =\"\"\n",
    "            name = i.name\n",
    "            ma_p = maskp\n",
    "            ma_p += name\n",
    "            sub_mask = imageio.imread(ma_p)\n",
    "            masks.append(sub_mask)\n",
    "\n",
    "        mask = masks[0]\n",
    "        for m in masks: \n",
    "            mask = np.where((mask + m) > 200, 255, 0)\n",
    "            #Finaly, we regroup every sub mask in a single one.\n",
    "\n",
    "\n",
    "        #We add the image and its mask to the dictionary    \n",
    "        training_set[idx] = (im, mask)\n",
    "        idx += 1\n",
    "    return idx, training_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perlin(x,y,seed=0):\n",
    "    # permutation table\n",
    "    np.random.seed(seed)\n",
    "    p = np.arange(256,dtype=int)\n",
    "    np.random.shuffle(p)\n",
    "    p = np.stack([p,p]).flatten()\n",
    "    # coordinates of the top-left\n",
    "    xi = x.astype(int)\n",
    "    yi = y.astype(int)\n",
    "    # internal coordinates\n",
    "    xf = x - xi\n",
    "    yf = y - yi\n",
    "    # fade factors\n",
    "    u = fade(xf)\n",
    "    v = fade(yf)\n",
    "    # noise components\n",
    "    n00 = gradient(p[p[xi]+yi],xf,yf)\n",
    "    n01 = gradient(p[p[xi]+yi+1],xf,yf-1)\n",
    "    n11 = gradient(p[p[xi+1]+yi+1],xf-1,yf-1)\n",
    "    n10 = gradient(p[p[xi+1]+yi],xf-1,yf)\n",
    "    # combine noises\n",
    "    x1 = lerp(n00,n10,u)\n",
    "    x2 = lerp(n01,n11,u) \n",
    "    return lerp(x1,x2,v) \n",
    "\n",
    "def lerp(a,b,x):\n",
    "    \"linear interpolation\"\n",
    "    return a + x * (b-a)\n",
    "\n",
    "def fade(t):\n",
    "    \"6t^5 - 15t^4 + 10t^3\"\n",
    "    return 6 * t**5 - 15 * t**4 + 10 * t**3\n",
    "\n",
    "def gradient(h,x,y):\n",
    "    \"grad converts h to the right gradient vector and return the dot product with (x,y)\"\n",
    "    vectors = np.array([[0,1],[0,-1],[1,0],[-1,0]])\n",
    "    g = vectors[h%4]\n",
    "    return g[:,:,0] * x + g[:,:,1] * y\n",
    "\n",
    "lin = np.linspace(0,2,256,endpoint=False)\n",
    "x,y = np.meshgrid(lin,lin)\n",
    "\n",
    "im_p = perlin(x,y,seed=random.randint(5,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "         Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "         Proc. of the International Conference on Document Analysis and\n",
    "         Recognition, 2003.\n",
    "\n",
    "     Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = image.shape\n",
    "    shape_size = shape[:2]\n",
    "    \n",
    "    # Random affine\n",
    "    center_square = np.float32(shape_size) // 2\n",
    "    square_size = min(shape_size) // 3\n",
    "    pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    image = cv2.warpAffine(image, M, shape_size, image,borderMode=cv2.BORDER_REFLECT_101)\n",
    "    \n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dz = np.zeros_like(dx)\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
    "\n",
    "\n",
    "\n",
    "def draw_grid(im, grid_size):\n",
    "    # Draw grid lines\n",
    "    for i in range(0, im.shape[1], grid_size):\n",
    "        cv2.line(im, (i, 0), (i, im.shape[0]), color=(255,))\n",
    "    for j in range(0, im.shape[0], grid_size):\n",
    "        cv2.line(im, (0, j), (im.shape[1], j), color=(255,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUnet(height,width,depth,kernel):\n",
    "    inputLayer = Input(( height, width, depth))\n",
    "\n",
    "    normalise = Lambda(lambda x: x / 255) (inputLayer)\n",
    "\n",
    "    conv11 = Conv2D(16, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(normalise)\n",
    "    conv12 = Conv2D(16, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(conv11)\n",
    "    pool1 = MaxPooling2D((2,2))(conv12)\n",
    "    conv21 = Conv2D(32, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(pool1)\n",
    "    conv22 = Conv2D(32, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(conv21)\n",
    "    pool2 = MaxPooling2D((2,2))(conv22)\n",
    "    conv31 = Conv2D(64, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(pool2)\n",
    "    conv32 = Conv2D(64, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(conv31)\n",
    "    pool3 = MaxPooling2D((2,2))(conv32)\n",
    "    conv41 = Conv2D(128, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(pool3)\n",
    "    conv42 = Conv2D(128, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(conv41)\n",
    "    pool4 = MaxPooling2D((2,2))(conv42)\n",
    "    conv51 = Conv2D(256, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(pool4)\n",
    "    conv52 = Conv2D(256, kernel, padding='valid', activation='relu', kernel_initializer='random_uniform')(conv51)\n",
    "\n",
    "\n",
    "\n",
    "    upconv1 = UpSampling2D(size=(2, 2))(conv52)\n",
    "    ch, cw = get_crop_shape(conv42, upconv1)\n",
    "    cropconv4 = Cropping2D(cropping=(ch,cw))(conv42)\n",
    "    up1   = concatenate([upconv1, cropconv4], axis=3)\n",
    "    conv61 = Conv2D(128, kernel, padding=\"valid\", activation=\"relu\", kernel_initializer='random_uniform')(up1)\n",
    "    conv62 = Conv2D(128, kernel, padding=\"valid\", activation=\"relu\", kernel_initializer='random_uniform')(conv61)\n",
    "\n",
    "\n",
    "    upconv2 = UpSampling2D(size=(2, 2))(conv62)\n",
    "    ch, cw = get_crop_shape(conv32, upconv2)\n",
    "    cropconv3 = Cropping2D(cropping=(ch,cw))(conv32)\n",
    "    up2  = concatenate([upconv2, cropconv3], axis=3)\n",
    "    conv71 = Conv2D(64, kernel, padding=\"valid\", activation=\"relu\", kernel_initializer='random_uniform')(up2)\n",
    "    conv72 = Conv2D(64, kernel, padding=\"valid\", activation=\"relu\", kernel_initializer='random_uniform')(conv71)\n",
    "\n",
    "\n",
    "    upconv3 = UpSampling2D(size=(2, 2))(conv72)\n",
    "    ch, cw = get_crop_shape(conv22, upconv3)\n",
    "    cropconv2 = Cropping2D(cropping=(ch,cw))(conv22)\n",
    "    up3  = concatenate([upconv3, cropconv2], axis=3)\n",
    "    conv81 = Conv2D(32, kernel, padding=\"valid\", activation=\"relu\", kernel_initializer='random_uniform')(up3)\n",
    "    conv82 = Conv2D(32, kernel, padding=\"valid\", activation=\"relu\", kernel_initializer='random_uniform')(conv81)\n",
    "\n",
    "    upconv4 = UpSampling2D(size=(2, 2))(conv82)\n",
    "    ch, cw = get_crop_shape(conv12, upconv4)\n",
    "    cropconv1 = Cropping2D(cropping=(ch,cw))(conv12)\n",
    "    up4  = concatenate([upconv4, cropconv1], axis=3)\n",
    "    conv91 = Conv2D(16, kernel, padding=\"valid\", activation=\"relu\", kernel_initializer='random_uniform')(up4)\n",
    "    conv92 = Conv2D(16, kernel, padding=\"valid\", activation=\"relu\", kernel_initializer='random_uniform')(conv91)\n",
    "\n",
    "    outputconv = Conv2D(1, (1, 1), activation=\"sigmoid\")(conv92)\n",
    "\n",
    "\n",
    "    u_net = Model(inputs= inputLayer, outputs = outputconv)\n",
    "    return u_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm\n",
    "\n",
    "def elastoperlin_transformation(im ,mask,elast, perl, shape):\n",
    "    lina = np.linspace(0,1,shape[0],endpoint=False)\n",
    "    linb = np.linspace(0,1,shape[1],endpoint=False)\n",
    "    a,b = np.meshgrid(linb,lina)\n",
    "    if perl:\n",
    "        im_p = perlin(a,b,seed=random.randint(1,20000))\n",
    "        im_p = np.abs(im_p)\n",
    "        im_p = np.array((normalize(im_p)*255), dtype = np.uint8)\n",
    "        #im_p = np.concatenate((im_p[...,None], im_p[...,None],im_p[...,None]), axis=2)\n",
    "        im = im + im_p\n",
    "    if elast:\n",
    "        im = np.concatenate((im[...,None], mask[...,None]), axis=2)\n",
    "        im = elastic_transform(im,im.shape[1]*2,im.shape[1]*0.1,im.shape[1]*0.08) \n",
    "        mask = im[:,:,1:]\n",
    "        im = im[:,:,0]\n",
    "    im = cv2.copyMakeBorder(im,92,92,92,92,cv2.BORDER_REFLECT) \n",
    "    # 92 représente la marge rognée par les convolutions successives\n",
    "    return im, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imaskdivision(im,mask,shape, padding):\n",
    "    # padding est la taille de la marge non masquée (92)\n",
    "    # shape est la shape maximale d'un echantillon (132,132) dans notre cas\n",
    "    ims = []\n",
    "    masks = []\n",
    "    widthDiv = int(np.ceil(float(im.shape[0]-(2*padding))/float(shape[0])))\n",
    "    heightDiv = int(np.ceil(float(im.shape[1]-(2*padding))/float(shape[1])))\n",
    "    for i in range(widthDiv):\n",
    "        for j in range(heightDiv):\n",
    "            if i == widthDiv-1:\n",
    "                sw = im.shape[0]-(shape[0]+padding)\n",
    "            else:\n",
    "                sw = padding + shape[0]*i\n",
    "                \n",
    "            if j == heightDiv-1:\n",
    "                sh = im.shape[1]-(shape[1]+padding)\n",
    "            else:\n",
    "                sh = padding + shape[1]*j\n",
    "            \n",
    "            imseg = im[sw-padding:sw+shape[0]+padding,sh-padding:sh+shape[1]+padding]\n",
    "            ims.append(imseg)\n",
    "            maskseg = mask[sw-padding:sw+shape[0]-padding,sh-padding:sh+shape[1]-padding]\n",
    "            maskseg = (maskseg>0)\n",
    "            masks.append(maskseg)\n",
    "    return ims,masks\n",
    "\n",
    "def dataAugmentation(im, mask, rate):\n",
    "    train = []\n",
    "    labels = []\n",
    "    for i in range(rate):\n",
    "        imtemp, masktemp = elastoperlin_transformation(im, mask, True, False,np.shape(im))\n",
    "        ims, masks = imaskdivision(imtemp, masktemp,(132,132),92)\n",
    "        for image in ims:\n",
    "            train.append(image)\n",
    "        for m in masks:\n",
    "            labels.append(m)\n",
    "    return train , labels        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def trainDatas(training_set, nbIms,rate):\n",
    "    train = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(nbIms):\n",
    "        im, mask = training_set[i]\n",
    "        ims , masks = dataAugmentation(im,mask,rate)\n",
    "        print i, \" images traitées\"\n",
    "        for image in ims:\n",
    "            train.append(np.reshape(image,(316,316,1)))\n",
    "        for m in masks:\n",
    "            labels.append(np.reshape(m, (132,132,1)))\n",
    "    train = np.array(train)\n",
    "    labels = np.array(labels)\n",
    "    return train ,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightLoss(y_true, y_pred):\n",
    "    [mask, weight] = tf.unstack(y_true, 2, axis=3)\n",
    "    weighted_pred = y_pred*weight\n",
    "    weighted_mask = mask*weight\n",
    "    return binary_crossentropy(weighted_mask, weighted_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des images et creation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images traitées\n",
      "1  images traitées\n",
      "2  images traitées\n",
      "3  images traitées\n",
      "4  images traitées\n",
      "5  images traitées\n"
     ]
    }
   ],
   "source": [
    "nbImagesUsables,trainingData = getData()\n",
    "imagesUsed = 6\n",
    "augDim = 1\n",
    "train, labels = trainDatas(trainingData,imagesUsed,augDim)\n",
    "del trainingData\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creation  du réseau et définition de la perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des variables\n",
    "height = 316\n",
    "width = 316\n",
    "depth = 1\n",
    "kernel= (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 316, 316, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 316, 316, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 314, 314, 16) 160         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 312, 312, 16) 2320        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 156, 156, 16) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 154, 154, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 152, 152, 32) 9248        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 76, 76, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 74, 74, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 72, 72, 64)   36928       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 36, 36, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 34, 34, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 256)  295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 12, 12, 256)  590080      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 24, 24, 256)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 24, 24, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 24, 24, 384)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 22, 22, 128)  442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 20, 20, 128)  147584      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 40, 40, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 40, 40, 192)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 38, 38, 64)   110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 36, 36, 64)   36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 72, 72, 64)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 72, 72, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 72, 72, 96)   0           up_sampling2d_3[0][0]            \n",
      "                                                                 cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 70, 70, 32)   27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 68, 68, 32)   9248        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 136, 136, 32) 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)       (None, 136, 136, 16) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 136, 136, 48) 0           up_sampling2d_4[0][0]            \n",
      "                                                                 cropping2d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 134, 134, 16) 6928        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 132, 132, 16) 2320        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 132, 132, 1)  17          conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,962,337\n",
      "Trainable params: 1,962,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "u_net = createUnet(height,width,depth,kernel)\n",
    "u_net.compile(optimizer='adam', loss='binary_crossentropy', metrics =[metrics.binary_accuracy])\n",
    "u_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22 samples, validate on 6 samples\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(patience=4, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018.h5', verbose=1, save_best_only=True)\n",
    "results = u_net.fit(train, labels, validation_split=0.2, batch_size=4, epochs=15, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction et visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = u_net.predict(train, batch_size = 1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(20):\n",
    "    \n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.imshow(train[k,92:224,92:224,0], interpolation=\"nearest\",cmap =\"Greys\")\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(np.reshape((p_test[k]),(132,132)), interpolation=\"nearest\",cmap =\"Greys\")\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(np.reshape(labels[k],(132,132)),interpolation=\"nearest\",cmap =\"Greys\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
